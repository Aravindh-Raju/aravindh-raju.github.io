---
title: "AWS Lambda Timeout Got You? Beat It with Recursion (and a Little JS Magic)"
categories:
  - Blog
tags:
  - AWS
  - Lambda
  - JavaScript
  - Serverless
  - Cloud
  - Tech
  - Software Development
---

Weâ€™ve all been there. You're building something cool with AWS Lambda â€” serverless, fast, simple. Everything's great... until you hit this dreaded limit:

> â€œLambda function timeout is limited to 900 seconds.â€

Yep. 15 minutes. Thatâ€™s all you get.

Now, if you're just resizing images or sending emails, no worries. But if youâ€™re processing a big list, running long API chains, or doing heavy I/O, youâ€™re out of luck â€” unless you get creative.

So, hereâ€™s the trick: **Let Lambda call itself.**

---

## ðŸ’¡ The Idea: Break It Down and Recurse

You canâ€™t make Lambda run longer than 15 minutes. Thatâ€™s non-negotiable.

But what you *can* do is break the task into smaller pieces. Let each function call process a chunk, and then â€” before it times out â€” have it invoke itself again to continue.

Each execution passes its progress (like `startIndex`) to the next one. And the loop continues until the jobâ€™s done.

Itâ€™s simple. Itâ€™s clean. And it works like magic.

---

## ðŸ§ª A Real Example: Processing 1000 Items in Batches

Letâ€™s say you have 1000 items to process, and you want to handle 100 at a time.

Hereâ€™s how youâ€™d do it in a Node.js Lambda:

```js
const AWS = require('aws-sdk');
const lambda = new AWS.Lambda();

const TOTAL_ITEMS = 1000;
const BATCH_SIZE = 100;

exports.handler = async (event) => {
  const startIndex = event?.startIndex || 0;
  const endIndex = Math.min(startIndex + BATCH_SIZE, TOTAL_ITEMS);

  console.log(`Processing items ${startIndex} to ${endIndex - 1}`);

  for (let i = startIndex; i < endIndex; i++) {
    // Pretend weâ€™re doing something useful here
    console.log(`Processed item ${i}`);
  }

  if (endIndex < TOTAL_ITEMS) {
    console.log(`Still more to go. Calling myself again from index ${endIndex}`);

    const params = {
      FunctionName: process.env.AWS_LAMBDA_FUNCTION_NAME,
      InvocationType: 'Event', // async call
      Payload: JSON.stringify({ startIndex: endIndex }),
    };

    await lambda.invoke(params).promise();
  } else {
    console.log("âœ… All items processed. Done and dusted!");
  }

  return {
    statusCode: 200,
    body: `Processed items ${startIndex} to ${endIndex - 1}`,
  };
};
```

---

## ðŸ§ â€œWait... doesnâ€™t `await lambda.invoke()` wait for the next function to finish?â€

This was my first question too. And itâ€™s an important one.

**Short answer:** No, it doesnâ€™t â€” *if* you use `'Event'` as the `InvocationType`.

Letâ€™s break it down:

| Invocation Type     | What it does                            | Does `await` wait? |
|---------------------|------------------------------------------|--------------------|
| `'RequestResponse'` | Synchronous. Waits for the result.       | âœ… Yes              |
| `'Event'`           | Asynchronous. Fire-and-forget.           | âŒ No               |
| `'DryRun'`          | Just validates permissions.              | âœ… N/A              |

With `'Event'`, the Lambda just **queues the new invocation and returns immediately**. It doesnâ€™t wait for the next one to finish â€” which is exactly what we want in a recursive setup.

Youâ€™re not waiting on yourself. Youâ€™re handing off the baton and exiting fast ðŸƒâ€â™‚ï¸ðŸ’¨

---

## ðŸ›  Pro Tips

- **Leave a buffer** â€” donâ€™t cut it too close to the 900-second timeout.
- Use **CloudWatch Logs** to monitor and debug each batch/run.
- Add retry and failure handling using **DLQ (Dead Letter Queue)**, or level up with **Step Functions**.
- If you want to run tasks in parallel, consider **SQS fan-out** instead of recursion.

---

## âœ… TL;DR

- Lambda has a **15-minute hard timeout**.  
- **Break the task into smaller chunks**.  
- **Recursively call your own Lambda** with updated progress.  
- Use `InvocationType: 'Event'` so the current function **doesnâ€™t wait**.  
- Keep your function lightweight, and let the chain continue.

Boom â€” infinite job execution, still fully serverless. ðŸš€

---

## Wanna Go Further?

You can take this same logic and plug it into **Step Functions** if you want visual workflows, retries, or branching. Or use the **Serverless Framework** to deploy everything without the boilerplate headache.

This pattern is super flexible â€” whether you're processing huge datasets, crawling pages, or running async jobs â€” it just works.

So go ahead: slice it, queue it, recurse it.
s
Happy hacking! ðŸ”ðŸ’»ðŸš€
